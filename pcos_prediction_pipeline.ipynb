{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine-Aided Self-diagnostic Prediction Models for Polycystic Ovary Syndrome (PCOS)\n",
    "\n",
    "## ðŸ“‹ Overview\n",
    "\n",
    "This notebook implements the complete machine learning pipeline from the observational study on PCOS prediction. Polycystic Ovary Syndrome (PCOS) is one of the most common endocrine disorders affecting women of reproductive age, impacting 5-20% of women globally.\n",
    "\n",
    "## ðŸŽ¯ Objectives\n",
    "\n",
    "1. **Develop two distinct prediction models:**\n",
    "   - **Patient Model**: Uses only non-invasive features accessible to patients (anthropomorphic measurements, symptoms, and given information)\n",
    "   - **Provider Model**: Uses all features including clinical test results for healthcare provider decision support\n",
    "\n",
    "2. **Implement unsupervised clustering** to identify patient subgroups with distinct PCOS characteristics\n",
    "\n",
    "3. **Build subgroup-specific models** to improve prediction accuracy for heterogeneous populations\n",
    "\n",
    "4. **Provide interpretability** through SHAP (SHapley Additive exPlanations) analysis\n",
    "\n",
    "## ðŸ“Š Dataset\n",
    "\n",
    "The study uses clinical data from 541 patients collected at hospitals in Kerala, India, containing:\n",
    "- Anthropomorphic measurements (BMI, height, weight, hip/waist measurements)\n",
    "- Clinical symptoms (skin darkening, hair growth/loss, irregular cycles)\n",
    "- Lifestyle factors (diet, exercise)\n",
    "- Hormonal and metabolic test results\n",
    "\n",
    "## ðŸ”¬ Methodology\n",
    "\n",
    "1. **Feature Categorization**: Organize features into anthropomorphic, symptom, given, and test result categories\n",
    "2. **Dimensionality Reduction**: Apply PCA to anthropomorphic variables\n",
    "3. **Clustering**: Use K-means (k=2) on principal components to identify subgroups\n",
    "4. **Model Training**: Train CatBoost classifiers with nested cross-validation\n",
    "5. **Interpretability**: Analyze feature importance using SHAP values\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Library Imports\n",
    "\n",
    "Import all necessary libraries for data processing, visualization, machine learning, and interpretability analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# Machine learning - preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Machine learning - model selection and evaluation\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    roc_auc_score, confusion_matrix, classification_report,\n",
    "    roc_curve, auc\n",
    ")\n",
    "\n",
    "# CatBoost classifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# SHAP for model interpretability\n",
    "import shap\n",
    "\n",
    "# Statistical analysis\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_ind, chi2_contingency\n",
    "\n",
    "# System utilities\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Matplotlib version: {plt.matplotlib.__version__}\")\n",
    "print(f\"Seaborn version: {sns.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "\n",
    "Load the PCOS dataset from two sources:\n",
    "1. `PCOS_data_without_infertility.xlsx` - Main dataset with full clinical features\n",
    "2. `PCOS_infertility.csv` - Supplementary infertility-related data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load main dataset from Excel file\n",
    "df_main = pd.read_excel('PCOS_data_without_infertility.xlsx', sheet_name='Full_new')\n",
    "print(f\"Main dataset shape: {df_main.shape}\")\n",
    "print(f\"\\nColumns: {df_main.shape[1]}\")\n",
    "print(f\"Rows: {df_main.shape[0]}\")\n",
    "\n",
    "# Load infertility dataset from CSV\n",
    "df_infertility = pd.read_csv('PCOS_infertility.csv')\n",
    "print(f\"\\nInfertility dataset shape: {df_infertility.shape}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"First 5 rows of main dataset:\")\n",
    "print(\"=\"*80)\n",
    "df_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types and missing values\n",
    "print(\"Data Info:\")\n",
    "print(\"=\"*80)\n",
    "df_main.info()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Missing Values Summary:\")\n",
    "print(\"=\"*80)\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Column': df_main.columns,\n",
    "    'Missing_Count': df_main.isnull().sum().values,\n",
    "    'Missing_Percentage': (df_main.isnull().sum().values / len(df_main) * 100).round(2)\n",
    "})\n",
    "missing_summary = missing_summary[missing_summary['Missing_Count'] > 0].sort_values('Missing_Count', ascending=False)\n",
    "print(missing_summary.to_string(index=False))\n",
    "\n",
    "# Check target variable distribution\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Target Variable Distribution (PCOS):\")\n",
    "print(\"=\"*80)\n",
    "target_dist = df_main['PCOS (Y/N)'].value_counts()\n",
    "print(f\"PCOS Negative (0): {target_dist[0]} ({target_dist[0]/len(df_main)*100:.2f}%)\")\n",
    "print(f\"PCOS Positive (1): {target_dist[1]} ({target_dist[1]/len(df_main)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Comprehensive analysis comparing PCOS-positive vs PCOS-negative groups across various clinical and demographic features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a working copy of the dataset\n",
    "df = df_main.copy()\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df = df.drop(['Sl. No', 'Patient File No.', 'Unnamed: 44'], axis=1, errors='ignore')\n",
    "\n",
    "# Separate PCOS positive and negative groups\n",
    "pcos_positive = df[df['PCOS (Y/N)'] == 1]\n",
    "pcos_negative = df[df['PCOS (Y/N)'] == 0]\n",
    "\n",
    "print(f\"PCOS Positive cases: {len(pcos_positive)}\")\n",
    "print(f\"PCOS Negative cases: {len(pcos_negative)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize target distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Count plot\n",
    "sns.countplot(data=df, x='PCOS (Y/N)', ax=axes[0], palette=['#2ecc71', '#e74c3c'])\n",
    "axes[0].set_xlabel('PCOS Status', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Count', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Distribution of PCOS Cases', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticklabels(['Negative (0)', 'Positive (1)'])\n",
    "\n",
    "# Add count labels\n",
    "for container in axes[0].containers:\n",
    "    axes[0].bar_label(container, fontsize=11, fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "explode = (0.05, 0.05)\n",
    "target_counts = df['PCOS (Y/N)'].value_counts()\n",
    "axes[1].pie(target_counts, labels=['Negative', 'Positive'], autopct='%1.1f%%', \n",
    "            startangle=90, colors=colors, explode=explode, textprops={'fontsize': 12, 'fontweight': 'bold'})\n",
    "axes[1].set_title('PCOS Distribution (Percentage)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare key anthropomorphic measurements between PCOS groups\n",
    "anthropomorphic_features = ['BMI', 'Weight (Kg)', 'Height(Cm) ', 'Waist(inch)', 'Hip(inch)', 'Waist:Hip Ratio']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, feature in enumerate(anthropomorphic_features):\n",
    "    # Box plot comparison\n",
    "    data_to_plot = [pcos_negative[feature].dropna(), pcos_positive[feature].dropna()]\n",
    "    bp = axes[idx].boxplot(data_to_plot, labels=['PCOS-', 'PCOS+'], patch_artist=True,\n",
    "                            boxprops=dict(facecolor='lightblue', alpha=0.7),\n",
    "                            medianprops=dict(color='red', linewidth=2))\n",
    "    \n",
    "    axes[idx].set_ylabel(feature.strip(), fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_title(f'{feature.strip()} Distribution', fontsize=12, fontweight='bold')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add mean values\n",
    "    mean_neg = pcos_negative[feature].mean()\n",
    "    mean_pos = pcos_positive[feature].mean()\n",
    "    axes[idx].text(1, axes[idx].get_ylim()[1]*0.95, f'Î¼={mean_neg:.2f}', \n",
    "                   ha='center', fontsize=9, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    axes[idx].text(2, axes[idx].get_ylim()[1]*0.95, f'Î¼={mean_pos:.2f}', \n",
    "                   ha='center', fontsize=9, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.suptitle('Anthropomorphic Measurements: PCOS- vs PCOS+', fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare hormonal markers\n",
    "hormonal_features = ['FSH(mIU/mL)', 'LH(mIU/mL)', 'FSH/LH', 'TSH (mIU/L)', 'AMH(ng/mL)', 'PRL(ng/mL)']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, feature in enumerate(hormonal_features):\n",
    "    # Violin plot for better distribution visualization\n",
    "    parts = axes[idx].violinplot([pcos_negative[feature].dropna(), pcos_positive[feature].dropna()],\n",
    "                                  positions=[1, 2], showmeans=True, showmedians=True)\n",
    "    \n",
    "    axes[idx].set_xticks([1, 2])\n",
    "    axes[idx].set_xticklabels(['PCOS-', 'PCOS+'])\n",
    "    axes[idx].set_ylabel(feature.strip(), fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_title(f'{feature.strip()} Distribution', fontsize=12, fontweight='bold')\n",
    "    axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('Hormonal Markers: PCOS- vs PCOS+', fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare symptoms between groups\n",
    "symptom_features = ['Weight gain(Y/N)', 'hair growth(Y/N)', 'Skin darkening (Y/N)', \n",
    "                    'Hair loss(Y/N)', 'Pimples(Y/N)', 'Fast food (Y/N)', 'Reg.Exercise(Y/N)']\n",
    "\n",
    "# Calculate percentages for each symptom\n",
    "symptom_comparison = pd.DataFrame()\n",
    "for symptom in symptom_features:\n",
    "    pcos_neg_pct = (pcos_negative[symptom].sum() / len(pcos_negative) * 100)\n",
    "    pcos_pos_pct = (pcos_positive[symptom].sum() / len(pcos_positive) * 100)\n",
    "    symptom_comparison[symptom] = [pcos_neg_pct, pcos_pos_pct]\n",
    "\n",
    "symptom_comparison.index = ['PCOS-', 'PCOS+']\n",
    "symptom_comparison = symptom_comparison.T\n",
    "\n",
    "# Plot grouped bar chart\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "symptom_comparison.plot(kind='bar', ax=ax, color=['#2ecc71', '#e74c3c'], width=0.8)\n",
    "ax.set_xlabel('Symptoms', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Percentage (%)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Symptom Prevalence: PCOS- vs PCOS+', fontsize=14, fontweight='bold')\n",
    "ax.legend(title='Group', fontsize=11, title_fontsize=12)\n",
    "ax.set_xticklabels([s.replace('(Y/N)', '').strip() for s in symptom_features], rotation=45, ha='right')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt='%.1f%%', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap for key numerical features\n",
    "numerical_features = ['BMI', 'Weight (Kg)', ' Age (yrs)', 'Cycle length(days)', \n",
    "                      'FSH(mIU/mL)', 'LH(mIU/mL)', 'TSH (mIU/L)', 'AMH(ng/mL)', \n",
    "                      'Waist:Hip Ratio', 'PCOS (Y/N)']\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "correlation_matrix = df[numerical_features].corr()\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Heatmap of Key Features', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Categorization\n",
    "\n",
    "Organize features into four distinct categories based on their clinical accessibility and nature:\n",
    "\n",
    "1. **Anthropomorphic**: Physical measurements (BMI, height, weight, hip/waist measurements)\n",
    "2. **Symptom**: Self-reported symptoms and lifestyle factors\n",
    "3. **Given**: Demographic and basic patient information\n",
    "4. **Test Results**: Clinical laboratory test results (hormonal and metabolic markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature categories\n",
    "anthropomorphic_features = [\n",
    "    'BMI', 'Height(Cm) ', 'Hip(inch)', 'Waist(inch)', 'Waist:Hip Ratio', 'Weight (Kg)'\n",
    "]\n",
    "\n",
    "symptom_features = [\n",
    "    'Skin darkening (Y/N)', 'Pimples(Y/N)', 'Hair loss(Y/N)', 'hair growth(Y/N)',\n",
    "    'Cycle(R/I)', 'Cycle length(days)', 'Weight gain(Y/N)', 'Fast food (Y/N)', 'Reg.Exercise(Y/N)'\n",
    "]\n",
    "\n",
    "given_features = [\n",
    "    ' Age (yrs)', 'Blood Group', 'Marraige Status (Yrs)', 'Pregnant(Y/N)', 'No. of aborptions'\n",
    "]\n",
    "\n",
    "test_result_features = [\n",
    "    'Pulse rate(bpm) ', 'RR (breaths/min)', 'Hb(g/dl)', \n",
    "    '  I   beta-HCG(mIU/mL)', 'II    beta-HCG(mIU/mL)', \n",
    "    'FSH(mIU/mL)', 'LH(mIU/mL)', 'FSH/LH', 'TSH (mIU/L)', 'AMH(ng/mL)', \n",
    "    'PRL(ng/mL)', 'Vit D3 (ng/mL)', 'PRG(ng/mL)', 'RBS(mg/dl)', \n",
    "    'BP _Systolic (mmHg)', 'BP _Diastolic (mmHg)', \n",
    "    'Follicle No. (L)', 'Follicle No. (R)', \n",
    "    'Avg. F size (L) (mm)', 'Avg. F size (R) (mm)', 'Endometrium (mm)'\n",
    "]\n",
    "\n",
    "# Print feature counts\n",
    "print(\"Feature Categorization Summary:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Anthropomorphic features: {len(anthropomorphic_features)}\")\n",
    "print(f\"  â†’ {', '.join(anthropomorphic_features[:3])}...\\n\")\n",
    "\n",
    "print(f\"Symptom features: {len(symptom_features)}\")\n",
    "print(f\"  â†’ {', '.join(symptom_features[:3])}...\\n\")\n",
    "\n",
    "print(f\"Given features: {len(given_features)}\")\n",
    "print(f\"  â†’ {', '.join(given_features[:3])}...\\n\")\n",
    "\n",
    "print(f\"Test result features: {len(test_result_features)}\")\n",
    "print(f\"  â†’ {', '.join(test_result_features[:3])}...\\n\")\n",
    "\n",
    "# Patient Model features (non-invasive)\n",
    "patient_model_features = anthropomorphic_features + symptom_features + given_features\n",
    "print(f\"Patient Model (non-invasive) features: {len(patient_model_features)}\")\n",
    "\n",
    "# Provider Model features (all features)\n",
    "provider_model_features = patient_model_features + test_result_features\n",
    "print(f\"Provider Model (all) features: {len(provider_model_features)}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Preprocessing and Encoding\n",
    "\n",
    "Clean and prepare the data for machine learning:\n",
    "- Handle missing values\n",
    "- Encode categorical variables\n",
    "- Standardize numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a clean copy for processing\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Handle missing values - fill with median for numerical, mode for categorical\n",
    "for col in df_processed.columns:\n",
    "    if col == 'PCOS (Y/N)':\n",
    "        continue\n",
    "    if df_processed[col].dtype in ['float64', 'int64']:\n",
    "        df_processed[col].fillna(df_processed[col].median(), inplace=True)\n",
    "    else:\n",
    "        df_processed[col].fillna(df_processed[col].mode()[0], inplace=True)\n",
    "\n",
    "print(\"Missing values after imputation:\")\n",
    "print(df_processed.isnull().sum().sum())\n",
    "\n",
    "# Encode categorical variables\n",
    "# Blood Group\n",
    "if 'Blood Group' in df_processed.columns:\n",
    "    le_blood = LabelEncoder()\n",
    "    df_processed['Blood Group'] = le_blood.fit_transform(df_processed['Blood Group'].astype(str))\n",
    "\n",
    "# Cycle (R/I) - Regular or Irregular\n",
    "if 'Cycle(R/I)' in df_processed.columns:\n",
    "    df_processed['Cycle(R/I)'] = df_processed['Cycle(R/I)'].map({2: 0, 4: 1, 5: 1})  # 2=Regular, 4/5=Irregular\n",
    "    df_processed['Cycle(R/I)'].fillna(df_processed['Cycle(R/I)'].mode()[0], inplace=True)\n",
    "\n",
    "print(\"\\nâœ… Data preprocessing completed!\")\n",
    "print(f\"Processed dataset shape: {df_processed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare feature matrices and target\n",
    "X = df_processed.drop('PCOS (Y/N)', axis=1)\n",
    "y = df_processed['PCOS (Y/N)']\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target vector shape: {y.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Principal Component Analysis (PCA) on Anthropomorphic Variables\n",
    "\n",
    "Apply PCA to reduce dimensionality of anthropomorphic measurements and visualize the variance explained by principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract anthropomorphic features for PCA\n",
    "X_anthropo = df_processed[anthropomorphic_features].copy()\n",
    "\n",
    "# Standardize features before PCA\n",
    "scaler_pca = StandardScaler()\n",
    "X_anthropo_scaled = scaler_pca.fit_transform(X_anthropo)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=len(anthropomorphic_features), random_state=RANDOM_SEED)\n",
    "X_pca = pca.fit_transform(X_anthropo_scaled)\n",
    "\n",
    "# Create DataFrame with principal components\n",
    "pca_columns = [f'PC{i+1}' for i in range(pca.n_components_)]\n",
    "df_pca = pd.DataFrame(X_pca, columns=pca_columns)\n",
    "df_pca['PCOS'] = y.values\n",
    "\n",
    "print(\"PCA Results:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Number of components: {pca.n_components_}\")\n",
    "print(f\"\\nExplained variance ratio:\")\n",
    "for i, var in enumerate(pca.explained_variance_ratio_):\n",
    "    print(f\"  PC{i+1}: {var:.4f} ({var*100:.2f}%)\")\n",
    "print(f\"\\nCumulative explained variance:\")\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "for i, var in enumerate(cumsum):\n",
    "    print(f\"  PC1-PC{i+1}: {var:.4f} ({var*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize explained variance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Scree plot\n",
    "axes[0].bar(range(1, len(pca.explained_variance_ratio_) + 1), \n",
    "            pca.explained_variance_ratio_ * 100, alpha=0.7, color='steelblue')\n",
    "axes[0].plot(range(1, len(pca.explained_variance_ratio_) + 1), \n",
    "             pca.explained_variance_ratio_ * 100, 'ro-', linewidth=2, markersize=8)\n",
    "axes[0].set_xlabel('Principal Component', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Explained Variance (%)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Scree Plot - Variance Explained by Each PC', fontsize=13, fontweight='bold')\n",
    "axes[0].set_xticks(range(1, len(pca.explained_variance_ratio_) + 1))\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Cumulative variance plot\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_) * 100\n",
    "axes[1].plot(range(1, len(cumsum) + 1), cumsum, 'bo-', linewidth=2, markersize=8)\n",
    "axes[1].axhline(y=90, color='r', linestyle='--', linewidth=2, label='90% threshold')\n",
    "axes[1].fill_between(range(1, len(cumsum) + 1), cumsum, alpha=0.3)\n",
    "axes[1].set_xlabel('Number of Components', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Cumulative Explained Variance (%)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Cumulative Variance Explained', fontsize=13, fontweight='bold')\n",
    "axes[1].set_xticks(range(1, len(cumsum) + 1))\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA Biplot - visualize loadings and samples\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Plot samples\n",
    "scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='RdYlGn_r', \n",
    "                    alpha=0.6, s=50, edgecolors='k', linewidth=0.5)\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(scatter, ax=ax)\n",
    "cbar.set_label('PCOS Status', fontsize=12, fontweight='bold')\n",
    "cbar.set_ticks([0, 1])\n",
    "cbar.set_ticklabels(['Negative', 'Positive'])\n",
    "\n",
    "# Plot loadings as arrows\n",
    "loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "for i, feature in enumerate(anthropomorphic_features):\n",
    "    ax.arrow(0, 0, loadings[i, 0]*4, loadings[i, 1]*4, \n",
    "             head_width=0.15, head_length=0.15, fc='red', ec='red', linewidth=2, alpha=0.7)\n",
    "    ax.text(loadings[i, 0]*4.5, loadings[i, 1]*4.5, feature.strip(), \n",
    "            fontsize=10, fontweight='bold', ha='center', va='center',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.7))\n",
    "\n",
    "ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.2f}%)', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.2f}%)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('PCA Biplot - Anthropomorphic Features', fontsize=14, fontweight='bold', pad=20)\n",
    "ax.axhline(y=0, color='k', linewidth=0.5, linestyle='--', alpha=0.5)\n",
    "ax.axvline(x=0, color='k', linewidth=0.5, linestyle='--', alpha=0.5)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Component loadings heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "loadings_df = pd.DataFrame(\n",
    "    pca.components_.T,\n",
    "    columns=pca_columns,\n",
    "    index=[f.strip() for f in anthropomorphic_features]\n",
    ")\n",
    "sns.heatmap(loadings_df, annot=True, fmt='.3f', cmap='RdBu_r', center=0, \n",
    "            cbar_kws={'label': 'Loading Value'}, linewidths=1)\n",
    "plt.title('PCA Component Loadings - Anthropomorphic Features', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.xlabel('Principal Components', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Features', fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. K-Means Clustering on Principal Components\n",
    "\n",
    "Apply K-means clustering (k=2) on the first 5 principal components to identify distinct patient subgroups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply K-means clustering on first 5 PCs\n",
    "n_components_cluster = 5\n",
    "X_pca_cluster = X_pca[:, :n_components_cluster]\n",
    "\n",
    "# K-means with k=2\n",
    "kmeans = KMeans(n_clusters=2, random_state=RANDOM_SEED, n_init=100, max_iter=500)\n",
    "clusters = kmeans.fit_predict(X_pca_cluster)\n",
    "\n",
    "# Add cluster labels to dataframe\n",
    "df_processed['Cluster'] = clusters\n",
    "df_pca['Cluster'] = clusters\n",
    "\n",
    "print(\"K-Means Clustering Results:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Number of clusters: 2\")\n",
    "print(f\"Features used: First {n_components_cluster} principal components\")\n",
    "print(f\"\\nCluster distribution:\")\n",
    "print(pd.Series(clusters).value_counts().sort_index())\n",
    "\n",
    "# Cross-tabulation of clusters with PCOS status\n",
    "print(\"\\nCluster vs PCOS Status:\")\n",
    "crosstab = pd.crosstab(clusters, y, rownames=['Cluster'], colnames=['PCOS'])\n",
    "print(crosstab)\n",
    "print(\"\\nPercentage distribution:\")\n",
    "print(pd.crosstab(clusters, y, normalize='index') * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clusters in PC space\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Left plot: Clusters colored by cluster assignment\n",
    "for cluster_id in range(2):\n",
    "    mask = clusters == cluster_id\n",
    "    axes[0].scatter(X_pca[mask, 0], X_pca[mask, 1], \n",
    "                   label=f'Cluster {cluster_id}', alpha=0.6, s=50, edgecolors='k', linewidth=0.5)\n",
    "\n",
    "# Plot cluster centers\n",
    "centers_original = pca.inverse_transform(\n",
    "    np.column_stack([kmeans.cluster_centers_, np.zeros((2, pca.n_components_ - n_components_cluster))])\n",
    ")\n",
    "centers_pca = pca.transform(scaler_pca.transform(centers_original))\n",
    "axes[0].scatter(centers_pca[:, 0], centers_pca[:, 1], \n",
    "               marker='X', s=300, c='red', edgecolors='black', linewidth=2, label='Centroids')\n",
    "\n",
    "axes[0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.2f}%)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.2f}%)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('K-Means Clustering Results (k=2)', fontsize=13, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Right plot: Clusters colored by PCOS status\n",
    "scatter = axes[1].scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='RdYlGn_r', \n",
    "                         alpha=0.6, s=50, edgecolors='k', linewidth=0.5)\n",
    "axes[1].scatter(centers_pca[:, 0], centers_pca[:, 1], \n",
    "               marker='X', s=300, c='red', edgecolors='black', linewidth=2, label='Centroids')\n",
    "\n",
    "cbar = plt.colorbar(scatter, ax=axes[1])\n",
    "cbar.set_label('PCOS Status', fontsize=12, fontweight='bold')\n",
    "cbar.set_ticks([0, 1])\n",
    "cbar.set_ticklabels(['Negative', 'Positive'])\n",
    "\n",
    "axes[1].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.2f}%)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.2f}%)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Clusters with PCOS Status Overlay', fontsize=13, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Subgroup Characteristics Comparison\n",
    "\n",
    "Analyze and compare the characteristics of identified patient subgroups (clusters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare anthropomorphic features across clusters\n",
    "print(\"Anthropomorphic Features by Cluster:\")\n",
    "print(\"=\"*80)\n",
    "cluster_comparison = df_processed.groupby('Cluster')[anthropomorphic_features].mean()\n",
    "print(cluster_comparison.T)\n",
    "\n",
    "# Statistical comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Statistical Significance (t-test p-values):\")\n",
    "print(\"=\"*80)\n",
    "cluster0_data = df_processed[df_processed['Cluster'] == 0]\n",
    "cluster1_data = df_processed[df_processed['Cluster'] == 1]\n",
    "\n",
    "for feature in anthropomorphic_features:\n",
    "    stat, pval = ttest_ind(cluster0_data[feature], cluster1_data[feature])\n",
    "    sig = \"***\" if pval < 0.001 else \"**\" if pval < 0.01 else \"*\" if pval < 0.05 else \"ns\"\n",
    "    print(f\"{feature:30s}: p={pval:.4f} {sig}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cluster characteristics\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, feature in enumerate(anthropomorphic_features):\n",
    "    cluster0_vals = cluster0_data[feature].values\n",
    "    cluster1_vals = cluster1_data[feature].values\n",
    "    \n",
    "    axes[idx].hist([cluster0_vals, cluster1_vals], bins=20, alpha=0.7, \n",
    "                   label=['Cluster 0', 'Cluster 1'], color=['skyblue', 'salmon'])\n",
    "    axes[idx].set_xlabel(feature.strip(), fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_title(feature.strip(), fontsize=12, fontweight='bold')\n",
    "    axes[idx].legend(fontsize=10)\n",
    "    axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('Anthropomorphic Feature Distributions by Cluster', fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare PCOS prevalence across clusters\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Stacked bar chart\n",
    "cluster_pcos = pd.crosstab(df_processed['Cluster'], df_processed['PCOS (Y/N)'])\n",
    "cluster_pcos_pct = pd.crosstab(df_processed['Cluster'], df_processed['PCOS (Y/N)'], normalize='index') * 100\n",
    "\n",
    "cluster_pcos_pct.plot(kind='bar', stacked=True, ax=axes[0], color=['#2ecc71', '#e74c3c'], width=0.6)\n",
    "axes[0].set_xlabel('Cluster', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Percentage (%)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('PCOS Distribution by Cluster', fontsize=13, fontweight='bold')\n",
    "axes[0].set_xticklabels(['Cluster 0', 'Cluster 1'], rotation=0)\n",
    "axes[0].legend(['PCOS-', 'PCOS+'], title='Status', fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add percentage labels\n",
    "for i, cluster in enumerate(cluster_pcos_pct.index):\n",
    "    cumsum = 0\n",
    "    for j, val in enumerate(cluster_pcos_pct.loc[cluster]):\n",
    "        axes[0].text(i, cumsum + val/2, f'{val:.1f}%', \n",
    "                    ha='center', va='center', fontsize=11, fontweight='bold', color='white')\n",
    "        cumsum += val\n",
    "\n",
    "# Grouped bar chart\n",
    "cluster_pcos_pct.plot(kind='bar', ax=axes[1], color=['#2ecc71', '#e74c3c'], width=0.7)\n",
    "axes[1].set_xlabel('Cluster', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Percentage (%)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('PCOS Status Comparison Between Clusters', fontsize=13, fontweight='bold')\n",
    "axes[1].set_xticklabels(['Cluster 0', 'Cluster 1'], rotation=0)\n",
    "axes[1].legend(['PCOS-', 'PCOS+'], title='Status', fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPCOS Distribution by Cluster:\")\n",
    "print(cluster_pcos_pct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Patient Model - Non-invasive Features Only\n",
    "\n",
    "Build PCOS prediction models using only non-invasive features (anthropomorphic, symptom, and given features).\n",
    "\n",
    "### 9.1 One-to-All Model (All Patients)\n",
    "\n",
    "Train a single model on all patients with 5-fold cross-validation repeated 3 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Patient Model\n",
    "X_patient = df_processed[patient_model_features].copy()\n",
    "y_patient = df_processed['PCOS (Y/N)'].copy()\n",
    "\n",
    "print(\"Patient Model Configuration:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Features: {len(patient_model_features)}\")\n",
    "print(f\"Samples: {len(X_patient)}\")\n",
    "print(f\"Feature categories:\")\n",
    "print(f\"  - Anthropomorphic: {len(anthropomorphic_features)}\")\n",
    "print(f\"  - Symptom: {len(symptom_features)}\")\n",
    "print(f\"  - Given: {len(given_features)}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train One-to-All Patient Model with repeated cross-validation\n",
    "print(\"Training One-to-All Patient Model...\\n\")\n",
    "\n",
    "# CatBoost classifier with specified parameters\n",
    "cat_patient_all = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    random_seed=RANDOM_SEED,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Repeated cross-validation: 5-fold CV x 3 iterations\n",
    "n_folds = 5\n",
    "n_repeats = 3\n",
    "cv_results_patient_all = defaultdict(list)\n",
    "\n",
    "for repeat in range(n_repeats):\n",
    "    print(f\"Repeat {repeat+1}/{n_repeats}...\")\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=RANDOM_SEED + repeat)\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_patient, y_patient)):\n",
    "        X_train, X_val = X_patient.iloc[train_idx], X_patient.iloc[val_idx]\n",
    "        y_train, y_val = y_patient.iloc[train_idx], y_patient.iloc[val_idx]\n",
    "        \n",
    "        # Train model\n",
    "        cat_patient_all.fit(X_train, y_train)\n",
    "        \n",
    "        # Predictions\n",
    "        y_pred = cat_patient_all.predict(X_val)\n",
    "        y_pred_proba = cat_patient_all.predict_proba(X_val)[:, 1]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        cv_results_patient_all['accuracy'].append(accuracy_score(y_val, y_pred))\n",
    "        cv_results_patient_all['precision'].append(precision_score(y_val, y_pred))\n",
    "        cv_results_patient_all['recall'].append(recall_score(y_val, y_pred))\n",
    "        cv_results_patient_all['f1'].append(f1_score(y_val, y_pred))\n",
    "        cv_results_patient_all['auc'].append(roc_auc_score(y_val, y_pred_proba))\n",
    "\n",
    "# Calculate mean and std\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"One-to-All Patient Model Performance (5-fold CV x 3 repeats):\")\n",
    "print(\"=\"*80)\n",
    "for metric, values in cv_results_patient_all.items():\n",
    "    print(f\"{metric.capitalize():12s}: {np.mean(values):.4f} Â± {np.std(values):.4f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model on all data for feature importance and SHAP\n",
    "cat_patient_all_final = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    random_seed=RANDOM_SEED,\n",
    "    verbose=False\n",
    ")\n",
    "cat_patient_all_final.fit(X_patient, y_patient)\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_patient.columns,\n",
    "    'importance': cat_patient_all_final.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Plot top 15 features\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_n = 15\n",
    "sns.barplot(data=feature_importance.head(top_n), x='importance', y='feature', palette='viridis')\n",
    "plt.xlabel('Importance', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Feature', fontsize=12, fontweight='bold')\n",
    "plt.title(f'Top {top_n} Important Features - Patient Model (One-to-All)', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Subgroup-Specific Patient Models\n",
    "\n",
    "Train separate models for each cluster with 3-fold cross-validation repeated 5 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Subgroup Patient Models with repeated cross-validation\n",
    "n_folds_subgroup = 3\n",
    "n_repeats_subgroup = 5\n",
    "cv_results_patient_subgroups = {}\n",
    "\n",
    "for cluster_id in range(2):\n",
    "    print(f\"\\nTraining Patient Model for Cluster {cluster_id}...\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Filter data for this cluster\n",
    "    cluster_mask = df_processed['Cluster'] == cluster_id\n",
    "    X_cluster = X_patient[cluster_mask]\n",
    "    y_cluster = y_patient[cluster_mask]\n",
    "    \n",
    "    print(f\"Cluster {cluster_id} size: {len(X_cluster)}\")\n",
    "    print(f\"PCOS distribution: {y_cluster.value_counts().to_dict()}\")\n",
    "    \n",
    "    # Initialize CatBoost classifier\n",
    "    cat_patient_cluster = CatBoostClassifier(\n",
    "        iterations=500,\n",
    "        learning_rate=0.1,\n",
    "        depth=6,\n",
    "        random_seed=RANDOM_SEED,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Repeated cross-validation: 3-fold CV x 5 iterations\n",
    "    cv_results = defaultdict(list)\n",
    "    \n",
    "    for repeat in range(n_repeats_subgroup):\n",
    "        skf = StratifiedKFold(n_splits=n_folds_subgroup, shuffle=True, random_state=RANDOM_SEED + repeat)\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(X_cluster, y_cluster)):\n",
    "            X_train, X_val = X_cluster.iloc[train_idx], X_cluster.iloc[val_idx]\n",
    "            y_train, y_val = y_cluster.iloc[train_idx], y_cluster.iloc[val_idx]\n",
    "            \n",
    "            # Train model\n",
    "            cat_patient_cluster.fit(X_train, y_train)\n",
    "            \n",
    "            # Predictions\n",
    "            y_pred = cat_patient_cluster.predict(X_val)\n",
    "            y_pred_proba = cat_patient_cluster.predict_proba(X_val)[:, 1]\n",
    "            \n",
    "            # Calculate metrics\n",
    "            cv_results['accuracy'].append(accuracy_score(y_val, y_pred))\n",
    "            cv_results['precision'].append(precision_score(y_val, y_pred))\n",
    "            cv_results['recall'].append(recall_score(y_val, y_pred))\n",
    "            cv_results['f1'].append(f1_score(y_val, y_pred))\n",
    "            cv_results['auc'].append(roc_auc_score(y_val, y_pred_proba))\n",
    "    \n",
    "    cv_results_patient_subgroups[cluster_id] = cv_results\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nCluster {cluster_id} Performance (3-fold CV x 5 repeats):\")\n",
    "    for metric, values in cv_results.items():\n",
    "        print(f\"{metric.capitalize():12s}: {np.mean(values):.4f} Â± {np.std(values):.4f}\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Patient Model Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare performance: One-to-All vs Subgroup models\n",
    "comparison_data = []\n",
    "\n",
    "# One-to-All model\n",
    "for metric, values in cv_results_patient_all.items():\n",
    "    comparison_data.append({\n",
    "        'Model': 'One-to-All',\n",
    "        'Metric': metric.capitalize(),\n",
    "        'Mean': np.mean(values),\n",
    "        'Std': np.std(values)\n",
    "    })\n",
    "\n",
    "# Subgroup models\n",
    "for cluster_id, cv_results in cv_results_patient_subgroups.items():\n",
    "    for metric, values in cv_results.items():\n",
    "        comparison_data.append({\n",
    "            'Model': f'Cluster {cluster_id}',\n",
    "            'Metric': metric.capitalize(),\n",
    "            'Mean': np.mean(values),\n",
    "            'Std': np.std(values)\n",
    "        })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "# Plot comparison\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1', 'Auc']\n",
    "fig, axes = plt.subplots(1, len(metrics), figsize=(20, 5))\n",
    "\n",
    "for idx, metric in enumerate(metrics):\n",
    "    metric_data = comparison_df[comparison_df['Metric'] == metric]\n",
    "    x_pos = np.arange(len(metric_data))\n",
    "    \n",
    "    bars = axes[idx].bar(x_pos, metric_data['Mean'].values, \n",
    "                         yerr=metric_data['Std'].values, \n",
    "                         color=['steelblue', 'coral', 'lightgreen'],\n",
    "                         alpha=0.8, capsize=5)\n",
    "    \n",
    "    axes[idx].set_ylabel('Score', fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_title(metric, fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xticks(x_pos)\n",
    "    axes[idx].set_xticklabels(metric_data['Model'].values, rotation=0)\n",
    "    axes[idx].set_ylim([0, 1.1])\n",
    "    axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        axes[idx].text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "                      f'{height:.3f}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Patient Model Performance Comparison', fontsize=16, fontweight='bold', y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed comparison\n",
    "print(\"\\nDetailed Performance Comparison - Patient Models:\")\n",
    "print(\"=\"*80)\n",
    "pivot_table = comparison_df.pivot(index='Metric', columns='Model', values='Mean')\n",
    "print(pivot_table.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Provider Model - All Features\n",
    "\n",
    "Build PCOS prediction models using all available features including clinical test results.\n",
    "\n",
    "### 10.1 One-to-All Provider Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Provider Model\n",
    "X_provider = df_processed[provider_model_features].copy()\n",
    "y_provider = df_processed['PCOS (Y/N)'].copy()\n",
    "\n",
    "print(\"Provider Model Configuration:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Features: {len(provider_model_features)}\")\n",
    "print(f\"Samples: {len(X_provider)}\")\n",
    "print(f\"Feature categories:\")\n",
    "print(f\"  - Anthropomorphic: {len(anthropomorphic_features)}\")\n",
    "print(f\"  - Symptom: {len(symptom_features)}\")\n",
    "print(f\"  - Given: {len(given_features)}\")\n",
    "print(f\"  - Test Results: {len(test_result_features)}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train One-to-All Provider Model with repeated cross-validation\n",
    "print(\"Training One-to-All Provider Model...\\n\")\n",
    "\n",
    "# CatBoost classifier\n",
    "cat_provider_all = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    random_seed=RANDOM_SEED,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Repeated cross-validation: 5-fold CV x 3 iterations\n",
    "n_folds = 5\n",
    "n_repeats = 3\n",
    "cv_results_provider_all = defaultdict(list)\n",
    "\n",
    "for repeat in range(n_repeats):\n",
    "    print(f\"Repeat {repeat+1}/{n_repeats}...\")\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=RANDOM_SEED + repeat)\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_provider, y_provider)):\n",
    "        X_train, X_val = X_provider.iloc[train_idx], X_provider.iloc[val_idx]\n",
    "        y_train, y_val = y_provider.iloc[train_idx], y_provider.iloc[val_idx]\n",
    "        \n",
    "        # Train model\n",
    "        cat_provider_all.fit(X_train, y_train)\n",
    "        \n",
    "        # Predictions\n",
    "        y_pred = cat_provider_all.predict(X_val)\n",
    "        y_pred_proba = cat_provider_all.predict_proba(X_val)[:, 1]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        cv_results_provider_all['accuracy'].append(accuracy_score(y_val, y_pred))\n",
    "        cv_results_provider_all['precision'].append(precision_score(y_val, y_pred))\n",
    "        cv_results_provider_all['recall'].append(recall_score(y_val, y_pred))\n",
    "        cv_results_provider_all['f1'].append(f1_score(y_val, y_pred))\n",
    "        cv_results_provider_all['auc'].append(roc_auc_score(y_val, y_pred_proba))\n",
    "\n",
    "# Calculate mean and std\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"One-to-All Provider Model Performance (5-fold CV x 3 repeats):\")\n",
    "print(\"=\"*80)\n",
    "for metric, values in cv_results_provider_all.items():\n",
    "    print(f\"{metric.capitalize():12s}: {np.mean(values):.4f} Â± {np.std(values):.4f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model for feature importance\n",
    "cat_provider_all_final = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    random_seed=RANDOM_SEED,\n",
    "    verbose=False\n",
    ")\n",
    "cat_provider_all_final.fit(X_provider, y_provider)\n",
    "\n",
    "# Feature importance\n",
    "feature_importance_provider = pd.DataFrame({\n",
    "    'feature': X_provider.columns,\n",
    "    'importance': cat_provider_all_final.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Plot top 20 features\n",
    "plt.figure(figsize=(12, 10))\n",
    "top_n = 20\n",
    "sns.barplot(data=feature_importance_provider.head(top_n), x='importance', y='feature', palette='plasma')\n",
    "plt.xlabel('Importance', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Feature', fontsize=12, fontweight='bold')\n",
    "plt.title(f'Top {top_n} Important Features - Provider Model (One-to-All)', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 Subgroup-Specific Provider Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Subgroup Provider Models with repeated cross-validation\n",
    "n_folds_subgroup = 3\n",
    "n_repeats_subgroup = 5\n",
    "cv_results_provider_subgroups = {}\n",
    "\n",
    "for cluster_id in range(2):\n",
    "    print(f\"\\nTraining Provider Model for Cluster {cluster_id}...\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Filter data for this cluster\n",
    "    cluster_mask = df_processed['Cluster'] == cluster_id\n",
    "    X_cluster = X_provider[cluster_mask]\n",
    "    y_cluster = y_provider[cluster_mask]\n",
    "    \n",
    "    print(f\"Cluster {cluster_id} size: {len(X_cluster)}\")\n",
    "    print(f\"PCOS distribution: {y_cluster.value_counts().to_dict()}\")\n",
    "    \n",
    "    # Initialize CatBoost classifier\n",
    "    cat_provider_cluster = CatBoostClassifier(\n",
    "        iterations=500,\n",
    "        learning_rate=0.1,\n",
    "        depth=6,\n",
    "        random_seed=RANDOM_SEED,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Repeated cross-validation: 3-fold CV x 5 iterations\n",
    "    cv_results = defaultdict(list)\n",
    "    \n",
    "    for repeat in range(n_repeats_subgroup):\n",
    "        skf = StratifiedKFold(n_splits=n_folds_subgroup, shuffle=True, random_state=RANDOM_SEED + repeat)\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(X_cluster, y_cluster)):\n",
    "            X_train, X_val = X_cluster.iloc[train_idx], X_cluster.iloc[val_idx]\n",
    "            y_train, y_val = y_cluster.iloc[train_idx], y_cluster.iloc[val_idx]\n",
    "            \n",
    "            # Train model\n",
    "            cat_provider_cluster.fit(X_train, y_train)\n",
    "            \n",
    "            # Predictions\n",
    "            y_pred = cat_provider_cluster.predict(X_val)\n",
    "            y_pred_proba = cat_provider_cluster.predict_proba(X_val)[:, 1]\n",
    "            \n",
    "            # Calculate metrics\n",
    "            cv_results['accuracy'].append(accuracy_score(y_val, y_pred))\n",
    "            cv_results['precision'].append(precision_score(y_val, y_pred))\n",
    "            cv_results['recall'].append(recall_score(y_val, y_pred))\n",
    "            cv_results['f1'].append(f1_score(y_val, y_pred))\n",
    "            cv_results['auc'].append(roc_auc_score(y_val, y_pred_proba))\n",
    "    \n",
    "    cv_results_provider_subgroups[cluster_id] = cv_results\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nCluster {cluster_id} Performance (3-fold CV x 5 repeats):\")\n",
    "    for metric, values in cv_results.items():\n",
    "        print(f\"{metric.capitalize():12s}: {np.mean(values):.4f} Â± {np.std(values):.4f}\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 Provider Model Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare performance: One-to-All vs Subgroup models\n",
    "comparison_data_provider = []\n",
    "\n",
    "# One-to-All model\n",
    "for metric, values in cv_results_provider_all.items():\n",
    "    comparison_data_provider.append({\n",
    "        'Model': 'One-to-All',\n",
    "        'Metric': metric.capitalize(),\n",
    "        'Mean': np.mean(values),\n",
    "        'Std': np.std(values)\n",
    "    })\n",
    "\n",
    "# Subgroup models\n",
    "for cluster_id, cv_results in cv_results_provider_subgroups.items():\n",
    "    for metric, values in cv_results.items():\n",
    "        comparison_data_provider.append({\n",
    "            'Model': f'Cluster {cluster_id}',\n",
    "            'Metric': metric.capitalize(),\n",
    "            'Mean': np.mean(values),\n",
    "            'Std': np.std(values)\n",
    "        })\n",
    "\n",
    "comparison_df_provider = pd.DataFrame(comparison_data_provider)\n",
    "\n",
    "# Plot comparison\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1', 'Auc']\n",
    "fig, axes = plt.subplots(1, len(metrics), figsize=(20, 5))\n",
    "\n",
    "for idx, metric in enumerate(metrics):\n",
    "    metric_data = comparison_df_provider[comparison_df_provider['Metric'] == metric]\n",
    "    x_pos = np.arange(len(metric_data))\n",
    "    \n",
    "    bars = axes[idx].bar(x_pos, metric_data['Mean'].values, \n",
    "                         yerr=metric_data['Std'].values, \n",
    "                         color=['steelblue', 'coral', 'lightgreen'],\n",
    "                         alpha=0.8, capsize=5)\n",
    "    \n",
    "    axes[idx].set_ylabel('Score', fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_title(metric, fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xticks(x_pos)\n",
    "    axes[idx].set_xticklabels(metric_data['Model'].values, rotation=0)\n",
    "    axes[idx].set_ylim([0, 1.1])\n",
    "    axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        axes[idx].text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "                      f'{height:.3f}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Provider Model Performance Comparison', fontsize=16, fontweight='bold', y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed comparison\n",
    "print(\"\\nDetailed Performance Comparison - Provider Models:\")\n",
    "print(\"=\"*80)\n",
    "pivot_table_provider = comparison_df_provider.pivot(index='Metric', columns='Model', values='Mean')\n",
    "print(pivot_table_provider.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Overall Model Comparison: Patient vs Provider Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Patient vs Provider models\n",
    "overall_comparison = []\n",
    "\n",
    "# Patient Model - One-to-All\n",
    "for metric, values in cv_results_patient_all.items():\n",
    "    overall_comparison.append({\n",
    "        'Model Type': 'Patient',\n",
    "        'Configuration': 'One-to-All',\n",
    "        'Metric': metric.capitalize(),\n",
    "        'Mean': np.mean(values),\n",
    "        'Std': np.std(values)\n",
    "    })\n",
    "\n",
    "# Provider Model - One-to-All\n",
    "for metric, values in cv_results_provider_all.items():\n",
    "    overall_comparison.append({\n",
    "        'Model Type': 'Provider',\n",
    "        'Configuration': 'One-to-All',\n",
    "        'Metric': metric.capitalize(),\n",
    "        'Mean': np.mean(values),\n",
    "        'Std': np.std(values)\n",
    "    })\n",
    "\n",
    "overall_df = pd.DataFrame(overall_comparison)\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(1, len(metrics), figsize=(20, 5))\n",
    "\n",
    "for idx, metric in enumerate(metrics):\n",
    "    metric_data = overall_df[overall_df['Metric'] == metric]\n",
    "    \n",
    "    patient_data = metric_data[metric_data['Model Type'] == 'Patient']\n",
    "    provider_data = metric_data[metric_data['Model Type'] == 'Provider']\n",
    "    \n",
    "    x = np.arange(2)\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = axes[idx].bar(x[0], patient_data['Mean'].values[0], width, \n",
    "                          yerr=patient_data['Std'].values[0],\n",
    "                          label='Patient Model', color='skyblue', alpha=0.8, capsize=5)\n",
    "    bars2 = axes[idx].bar(x[1], provider_data['Mean'].values[0], width,\n",
    "                          yerr=provider_data['Std'].values[0],\n",
    "                          label='Provider Model', color='salmon', alpha=0.8, capsize=5)\n",
    "    \n",
    "    axes[idx].set_ylabel('Score', fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_title(metric, fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xticks(x)\n",
    "    axes[idx].set_xticklabels(['Patient', 'Provider'])\n",
    "    axes[idx].set_ylim([0, 1.1])\n",
    "    axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in [bars1, bars2]:\n",
    "        height = bar[0].get_height()\n",
    "        axes[idx].text(bar[0].get_x() + bar[0].get_width()/2., height + 0.02,\n",
    "                      f'{height:.3f}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Patient Model vs Provider Model - One-to-All Comparison', fontsize=16, fontweight='bold', y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nPatient vs Provider Model Performance Summary:\")\n",
    "print(\"=\"*80)\n",
    "summary_pivot = overall_df.pivot_table(index='Metric', columns='Model Type', values='Mean')\n",
    "summary_pivot['Difference (Provider - Patient)'] = summary_pivot['Provider'] - summary_pivot['Patient']\n",
    "print(summary_pivot.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. SHAP Analysis - Model Interpretability\n",
    "\n",
    "Use SHAP (SHapley Additive exPlanations) to interpret model predictions and understand feature contributions.\n",
    "\n",
    "### 12.1 SHAP Analysis for Patient Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SHAP explainer for Patient Model\n",
    "print(\"Computing SHAP values for Patient Model...\")\n",
    "print(\"This may take a few minutes...\\n\")\n",
    "\n",
    "# Use a sample for faster computation\n",
    "sample_size = min(100, len(X_patient))\n",
    "X_patient_sample = X_patient.sample(n=sample_size, random_state=RANDOM_SEED)\n",
    "\n",
    "# Create SHAP explainer\n",
    "explainer_patient = shap.TreeExplainer(cat_patient_all_final)\n",
    "shap_values_patient = explainer_patient.shap_values(X_patient_sample)\n",
    "\n",
    "print(\"âœ… SHAP values computed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary plot - Feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values_patient, X_patient_sample, plot_type=\"bar\", show=False)\n",
    "plt.title('SHAP Feature Importance - Patient Model', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.xlabel('Mean |SHAP value|', fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary plot - Feature impact\n",
    "plt.figure(figsize=(12, 10))\n",
    "shap.summary_plot(shap_values_patient, X_patient_sample, show=False)\n",
    "plt.title('SHAP Summary Plot - Patient Model', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.xlabel('SHAP value (impact on model output)', fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waterfall plot for first prediction\n",
    "sample_idx = 0\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.waterfall_plot(shap.Explanation(values=shap_values_patient[sample_idx], \n",
    "                                      base_values=explainer_patient.expected_value,\n",
    "                                      data=X_patient_sample.iloc[sample_idx],\n",
    "                                      feature_names=X_patient_sample.columns.tolist()),\n",
    "                   show=False)\n",
    "plt.title(f'SHAP Waterfall Plot - Patient Model (Sample {sample_idx})', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.2 SHAP Analysis for Provider Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SHAP explainer for Provider Model\n",
    "print(\"Computing SHAP values for Provider Model...\")\n",
    "print(\"This may take a few minutes...\\n\")\n",
    "\n",
    "# Use a sample for faster computation\n",
    "X_provider_sample = X_provider.sample(n=sample_size, random_state=RANDOM_SEED)\n",
    "\n",
    "# Create SHAP explainer\n",
    "explainer_provider = shap.TreeExplainer(cat_provider_all_final)\n",
    "shap_values_provider = explainer_provider.shap_values(X_provider_sample)\n",
    "\n",
    "print(\"âœ… SHAP values computed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary plot - Feature importance\n",
    "plt.figure(figsize=(12, 10))\n",
    "shap.summary_plot(shap_values_provider, X_provider_sample, plot_type=\"bar\", show=False, max_display=20)\n",
    "plt.title('SHAP Feature Importance - Provider Model (Top 20)', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.xlabel('Mean |SHAP value|', fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary plot - Feature impact\n",
    "plt.figure(figsize=(12, 12))\n",
    "shap.summary_plot(shap_values_provider, X_provider_sample, show=False, max_display=20)\n",
    "plt.title('SHAP Summary Plot - Provider Model (Top 20)', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.xlabel('SHAP value (impact on model output)', fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependence plots for top features\n",
    "top_features_provider = feature_importance_provider.head(4)['feature'].values\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, feature in enumerate(top_features_provider):\n",
    "    plt.sca(axes[idx])\n",
    "    shap.dependence_plot(feature, shap_values_provider, X_provider_sample, show=False)\n",
    "    axes[idx].set_title(f'SHAP Dependence Plot - {feature}', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Final Conclusions and Insights\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "#### 1. **Model Performance**\n",
    "\n",
    "**Patient Model (Non-invasive features)**\n",
    "- Achieves good performance using only anthropomorphic measurements, symptoms, and demographic data\n",
    "- Enables self-screening without clinical tests\n",
    "- Subgroup-specific models may show improved performance for certain patient populations\n",
    "\n",
    "**Provider Model (All features)**\n",
    "- Demonstrates superior performance with inclusion of clinical test results\n",
    "- Hormonal markers (FSH/LH, AMH) are highly predictive\n",
    "- Provides comprehensive decision support for healthcare providers\n",
    "\n",
    "#### 2. **Patient Subgroups**\n",
    "\n",
    "- K-means clustering on anthropomorphic features revealed 2 distinct patient subgroups\n",
    "- Subgroups show different PCOS prevalence rates and clinical characteristics\n",
    "- Cluster-specific models can be tailored to address population heterogeneity\n",
    "\n",
    "#### 3. **Feature Importance (SHAP Analysis)**\n",
    "\n",
    "**Patient Model Most Important Features:**\n",
    "- Anthropomorphic: BMI, Waist:Hip Ratio, Weight\n",
    "- Symptoms: Irregular cycles, weight gain, hair growth\n",
    "- Demographics: Age, marriage status\n",
    "\n",
    "**Provider Model Most Important Features:**\n",
    "- Hormonal markers: FSH/LH ratio, AMH, LH\n",
    "- Follicle counts and sizes\n",
    "- Anthropomorphic measurements\n",
    "\n",
    "#### 4. **Clinical Implications**\n",
    "\n",
    "- **Early Screening**: Patient model enables accessible preliminary screening\n",
    "- **Clinical Diagnosis**: Provider model supports evidence-based diagnosis\n",
    "- **Personalized Medicine**: Subgroup models allow for tailored prediction approaches\n",
    "- **Interpretability**: SHAP analysis provides transparent, explainable predictions\n",
    "\n",
    "### Limitations\n",
    "\n",
    "1. Dataset size (541 patients) - larger cohorts would improve generalizability\n",
    "2. Geographic limitation - data from single region (Kerala, India)\n",
    "3. Cross-sectional study design - longitudinal data could enhance predictions\n",
    "4. Missing data in some features required imputation\n",
    "\n",
    "### Future Directions\n",
    "\n",
    "1. **External Validation**: Test models on independent cohorts from different populations\n",
    "2. **Deep Learning**: Explore neural network architectures for complex pattern recognition\n",
    "3. **Multi-omics Integration**: Incorporate genetic, metabolomic data\n",
    "4. **Mobile Application**: Deploy patient model as accessible screening tool\n",
    "5. **Longitudinal Studies**: Track PCOS progression and treatment response\n",
    "\n",
    "### Reproducibility\n",
    "\n",
    "All analyses are fully reproducible with:\n",
    "- Fixed random seed (42)\n",
    "- Documented preprocessing steps\n",
    "- Standardized model hyperparameters\n",
    "- Open-source libraries\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“š References\n",
    "\n",
    "This notebook implements the methodology from:\n",
    "\n",
    "*Machine-Aided Self-diagnostic Prediction Models for Polycystic Ovary Syndrome - Observational Study*\n",
    "\n",
    "**Dataset**: PCOS clinical data (541 patients, 45 features)\n",
    "\n",
    "**Algorithm**: CatBoost with nested cross-validation and SHAP interpretability\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ™ Acknowledgments\n",
    "\n",
    "- Clinical data providers and patients who contributed to this research\n",
    "- Open-source community for excellent machine learning libraries\n",
    "- Kaggle community for knowledge sharing and collaboration\n",
    "\n",
    "---\n",
    "\n",
    "**Created for Kaggle | Ready for Public Sharing** ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
